{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040cdec8-d8b3-4844-a7ab-4b74f6b0d2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyodbc\n",
    "from datetime import datetime\n",
    "from getpass import getpass\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*pandas only supports SQLAlchemy connectable.*\")\n",
    "# --- Step 1: Read connection string ---\n",
    "try:\n",
    "    conn_str = (\n",
    "    \"DRIVER={ODBC Driver 17 for SQL Server};\"\n",
    "    \"SERVER=ge-prd.database.windows.net;\"\n",
    "    \"DATABASE=GreenEnergy_DBP;\"\n",
    "    \"UID=Nalinpgdde@chndsrnvsgmail.onmicrosoft.com;\"\n",
    "    \"PWD=Neilapple7#;\"\n",
    "    \"Authentication=ActiveDirectoryPassword;\"\n",
    "    \"Encrypt=yes;\"\n",
    "    \"TrustServerCertificate=no;\"\n",
    ")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"Connection string file 'sql_cred.txt' not found!\")\n",
    "\n",
    "# --- Step 2: Connect to SQL Server ---\n",
    "conn = pyodbc.connect(conn_str)\n",
    "cursor = conn.cursor()\n",
    "cursor.fast_executemany = True\n",
    "\n",
    "# --- Step 3: Load staging data ---\n",
    "query = \"SELECT * FROM GreenEnergy_DBP.dbo.energy_data_STG WHERE ETL_LOAD_FLAG = 0\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# --- Step 4: Data enrichment ---\n",
    "df['day'] = pd.to_datetime(df['datetime']).dt.date\n",
    "df['hour'] = pd.to_datetime(df['datetime']).dt.hour\n",
    "\n",
    "# --- Step 5: Optional local backup ---\n",
    "df.to_csv('nightly_energy_dump.csv', index=False)\n",
    "print(\"ETL ingestion completed.\")\n",
    "\n",
    "# --- Step 6: Aggregation logic ---\n",
    "agg = df.groupby(['day', 'hour']).agg({\n",
    "    'consumption_kwh': ['mean', 'max'],\n",
    "    'solar_generation_kwh': 'sum',\n",
    "    'temperature_C': 'mean',\n",
    "    'humidity_percent': 'mean',\n",
    "    'wind_speed_kmph': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns\n",
    "agg.columns = [\n",
    "    'day', 'hour', 'avg_consumption_kwh', 'peak_consumption_kwh',\n",
    "    'solar_output_kwh', 'avg_temperature', 'avg_humidity', 'avg_wind_speed'\n",
    "]\n",
    "\n",
    "# --- Step 7: Prepare insert data ---\n",
    "bulk_data = []\n",
    "for _, row in agg.iterrows():\n",
    "    dt = datetime.combine(row.day, pd.Timestamp(row.hour, unit='h').time())\n",
    "    record = (\n",
    "        dt, row.hour, row.day,\n",
    "        float(row.avg_consumption_kwh), float(row.peak_consumption_kwh),\n",
    "        float(row.avg_temperature), float(row.avg_humidity),\n",
    "        float(row.avg_wind_speed), float(row.solar_output_kwh)\n",
    "    )\n",
    "    bulk_data.append(record)\n",
    "\n",
    "# --- Step 8: Sanity check for nulls ---\n",
    "for i, record in enumerate(bulk_data):\n",
    "    if any(val is None or pd.isnull(val) for val in record):\n",
    "        print(f\"‚ö†Ô∏è Null detected in row {i}: {record}\")\n",
    "        raise ValueError(\"Null value detected in insert data.\")\n",
    "\n",
    "# --- Step 9: Insert in chunks ---\n",
    "def chunks(data, size):\n",
    "    for i in range(0, len(data), size):\n",
    "        yield data[i:i + size]\n",
    "\n",
    "chunk_size = 5000\n",
    "total_rows = len(bulk_data)\n",
    "print(f\"\\nüöÄ Starting insert of {total_rows} rows in chunks of {chunk_size}...\")\n",
    "\n",
    "try:\n",
    "    for i, chunk in enumerate(chunks(bulk_data, chunk_size)):\n",
    "        cursor.executemany(\"\"\"\n",
    "            INSERT INTO GreenEnergy_DBP.dbo.energy_features\n",
    "            (datetime, hour, day, avg_consumption_kwh, peak_consumption_kwh,\n",
    "             avg_temperature, avg_humidity, avg_wind_speed, solar_output_kwh)\n",
    "            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\", chunk)\n",
    "        conn.commit()\n",
    "        print(f\"‚úÖ Chunk {i+1} inserted ({len(chunk)} rows).\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Insert failed: {e}\")\n",
    "    conn.rollback()\n",
    "    raise\n",
    "\n",
    "# --- Step 10: Update ETL flag in staging table ---\n",
    "try:\n",
    "    update_query = \"\"\"\n",
    "    UPDATE GreenEnergy_DBP.dbo.energy_data_STG\n",
    "    SET ETL_LOAD_FLAG = 1\n",
    "    WHERE ETL_LOAD_FLAG = 0\n",
    "    \"\"\"\n",
    "    cursor.execute(update_query)\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ ETL_LOAD_FLAG updated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to update ETL flag: {e}\")\n",
    "    conn.rollback()\n",
    "    raise\n",
    "\n",
    "# --- Step 11: Cleanup ---\n",
    "conn.close()\n",
    "print(\"üéâ All tasks completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049ec9e8-0e91-437b-97d0-7ea599c57c33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
